name: Run Jupyter Notebook and Email Output

on:
  # Schedule for the full report
  schedule:
    - cron: '01 00 * * *'  # Runs at 00:01 AM UTC daily
    - cron: '01 08 * * *'  # Runs at 08:01 AM UTC daily
  # Schedule for hourly updates
    - cron: '15 7-23 * * *'  # Runs hourly between 7 AM and 11 PM UTC
  workflow_dispatch:  # Allows manual triggering of the workflow

jobs:
  run-notebook:
    runs-on: ubuntu-latest

    steps:
      # For checking initial file state
      - name: Debug File Listing
        run: ls -al

      # Check out the code from the repo
      - name: Checkout repo
        uses: actions/checkout@v3

      # Compute a hash for park_data.json to be cached
      - name: Compute cache key for park_data.json
        id: cache-key
        run: |
          if [ -f park_data.json ]; then
            key_hash=$(sha256sum park_data.json | cut -d' ' -f1)
          else
            key_hash="no-file"
          fi
          echo "key=park-data-cache-${key_hash}-run-${{ github.run_number }}" >> $GITHUB_ENV
        shell: bash

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      # Restore cached park_data.json
      - name: Restore cache
        uses: actions/cache@v3
        id: cache-park-data
        with:
          path: park_data.json
          key: ${{ env.key }}
          restore-keys: |
            park-data-cache-

      # Debug park_data.json before running notebook
      - name: Print park_data.json content (before)
        run: |
          if [ -f park_data.json ]; then
            echo "Loaded park_data.json:"
            cat park_data.json
          else
            echo "No park_data.json found."
          fi

      # Install dependencies
      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      # Run the Jupyter Notebook
      - name: Run Jupyter Notebook
        run: |
          if [ -f park_data.json ]; then
            echo "Previous park_data.json found and will be used."
          else
            echo "No previous park_data.json found; starting fresh."
          fi
          jupyter nbconvert --to notebook --execute hackney_tennis_auto_booking.ipynb --output result.ipynb --ExecutePreprocessor.timeout=600 --stdout
        shell: bash

      # Debug park_data.json after running notebook
      - name: Print park_data.json content (after)
        run: |
          if [ -f park_data.json ]; then
            echo "Updated park_data.json:"
            cat park_data.json
          else
            echo "No park_data.json found after notebook run!"
          fi

      # Save updated park_data.json to cache
      - name: Save updated cache
        uses: actions/cache@v3
        with:
          path: park_data.json
          key: ${{ env.key }}

      # Debug File Listing after notebook execution
      - name: Debug File Listing
        run: ls -al

      # Send Email Logic
      - name: Determine and Send Email
        env:
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          SENDGRID_SENDER_EMAIL: ${{ secrets.SENDGRID_SENDER_EMAIL }}
          SENDGRID_RECIPIENT_EMAIL: ${{ secrets.SENDGRID_RECIPIENT_EMAIL }}
        run: |
          # Send hourly updates email if applicable
          if [ -f "availability_updates.html" ]; then
            if [[ "${{ github.event_name }}" == "schedule" && "${{ github.event.schedule }}" =~ "15 7-23" ]]; then
              echo "Hourly update with availability updates found. Sending email."
              python send_email_availability_updates.py
            fi
          else
            echo "No availability updates found for hourly updates."
          fi

          # Send full availability email on the full report schedule
          if [[ "${{ github.event_name }}" == "schedule" && ("${{ github.event.schedule }}" == "01 00 * * *" || "${{ github.event.schedule }}" == "01 08 * * *") ]]; then
            echo "Full report schedule. Sending full report email."
            python send_email_full_availability.py
          fi
